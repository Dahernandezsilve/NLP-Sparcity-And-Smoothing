{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7f6821",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <td style=\"width:20%; vertical-align:middle;\">\n",
    "      <img src=\"LogoUVG.png\" width=\"400\"/>\n",
    "    </td>\n",
    "    <td style=\"text-align:left; vertical-align:middle;\">\n",
    "      <h2 style=\"margin-bottom: 0;\">Universidad del Valle de Guatemala - UVG</h2>\n",
    "      <h3 style=\"margin-top: 0;\">Facultad de Ingeniería - Computación</h3>\n",
    "      <p style=\"font-size: 16px; margin-bottom: 0; margin-top: -20px\">\n",
    "        <strong>Curso:</strong> Procesamiento de Lenguaje Natural \n",
    "        <strong>Sección:</strong> 10\n",
    "      </p>\n",
    "      <p style=\"font-size: 16px; margin: 0;\"><strong>Laboratorio 4:</strong> Modelos de Lenguaje con N-gramas, Espacidad y Suavizado</p>\n",
    "      <br>\n",
    "      <p style=\"font-size: 15px; margin: 0;\"><strong>Autor:</strong></p>\n",
    "      <ul style=\"margin-top: 5px; padding-left: 20px; font-size: 15px;\">\n",
    "        <li>Diego Alexander Hernández Silvestre - <strong>21270</strong></li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "729c2128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     C:\\Users\\daher\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('cess_esp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c39a7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk import ngrams, ConditionalFreqDist\n",
    "from nltk.lm import KneserNeyInterpolated\n",
    "from nltk.corpus import cess_esp\n",
    "from nltk.util import ngrams\n",
    "import pandas as pd\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "97f93e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CESS-ESP corpus\n",
    "corpus = cess_esp.sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46eb6af",
   "metadata": {},
   "source": [
    "# Preprocesamiento del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577ca94",
   "metadata": {},
   "source": [
    "Para que los modelos funcionen óptimamente, se procede a realizar la estandarización del corpus proporcionado. El primer elemento detectado es que el corpus utiliza marcas para identificar patrones sintácticos. Por ejemplo -Fpa-, -Fpt- y *0*, pero como el objetivo del laboratorio es generar texto fluido con n-gramas, se procede a filtrarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b788ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpecialTags(sentences):\n",
    "    \"\"\"\n",
    "    Elimina tokens como -Fpa-, -Fpt- (rodeados por guiones)\n",
    "    y tokens como *0*, *1* (placeholders de anotación sintáctica)\n",
    "    en el corpus cess_esp.\n",
    "    \"\"\"\n",
    "    cleaned = []\n",
    "    for sentence in sentences:\n",
    "        cleaned_sentence = [\n",
    "            word for word in sentence\n",
    "            if not (word.startswith('-') and word.endswith('-'))  # -Fpa-, -Fpt-\n",
    "            and not re.fullmatch(r\"\\*\\d+\\*\", word)                # *0*, *1*, etc.\n",
    "        ]\n",
    "        cleaned.append(cleaned_sentence)\n",
    "    return cleaned\n",
    "\n",
    "comments = removeSpecialTags(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "83958d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El grupo estatal Electricité_de_France EDF anunció hoy , jueves , la compra del 51_por_ciento de la empresa mexicana Electricidad_Águila_de_Altamira EAA , creada por el japonés Mitsubishi_Corporation para poner_en_marcha una central de gas de 495 megavatios .',\n",
       " 'Una portavoz de EDF explicó a EFE que el proyecto para la construcción de Altamira_2 , al norte de Tampico , prevé la utilización de gas natural como combustible principal en una central de ciclo combinado que debe empezar a funcionar en mayo_del_2002 .',\n",
       " 'La electricidad producida pasará a la red eléctrica pública de México en_virtud_de un acuerdo de venta de energía de EAA con la Comisión_Federal_de_Electricidad CFE por una duración de 25 años .',\n",
       " 'EDF , que no quiso revelar cuánto pagó por su participación mayoritaria en EAA , intervendrá como asistente en la construcción de Altamira_2 y , posteriormente , se encargará de explotarla como principal accionista .',\n",
       " 'EDF y Mitsubishi participaron en 1998 en la licitación de licencias para construir centrales eléctricas en México y se quedaron con dos cada una : Río_Bravo y Saltillo para la compañía francesa y Altamira y Tuxpán para la japonesa .',\n",
       " 'EDF tiene previsto invertir 194 millones de euros 186 millones de dólares en la central de Río_Bravo , con una potencia de 495 megavatios , y 134 millones de euros 28 millones de dólares en Saltillo , que como la primera funcionará con gas natural y cuya potencia prevista es de 247 megavatios .',\n",
       " 'La alcaldesa de Málaga y cabeza de lista del PP al Congreso por esta provincia , Celia_Villalobos , pidió hoy a los militantes de esta formación que sepan \" administrar la victoria \" , porque \" no vale la revancha , el insulto o el ataque , eso es para ellos \" .',\n",
       " 'En una intervención ante militantes populares en el hotel de la capital malagueña elegido como sede de la noche electoral del PP , Villalobos dio las gracias \" a los militantes de muchos años que hoy tienen una emoción especial \" , y se confesó también \" especialmente emocionada \" en sus quintas elecciones generales .',\n",
       " 'La diputada electa transmitió \" un abrazo y mi cariño a José_María_Aznar \" , a quien definió como \" el hombre que ha sabido llevar al PP hasta la victoria \" , y dio las gracias a la \" gente que ha sabido ilusionar y convencer a muchos para que apuesten \" por este partido .',\n",
       " 'A todas estas personas \" no las vamos a defraudar \" , aseguró Villalobos , que subrayó que Aznar \" seguirá gobernando desde el diálogo , sin prepotencia , con honradez y preocupado por los problemas , y seguiremos siendo los mismos \" .']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = [' '.join(sent) for sent in comments]\n",
    "comments[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a940be",
   "metadata": {},
   "source": [
    "Se buscar analizar el efecto de la estandarización para identificar si existen apariciones de nuevas palabras con más repeticiones o simplemente, aumenta el número de las que actualmente se encuentran como más frecuentes. Para esto, se mostraran las 8 palabras más frecuentes antes del proceso y después del mismo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "88b54a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 8 common words:\n",
      "[(',', 11420), ('de', 10234), ('la', 6412), ('.', 5866), ('que', 5552), ('el', 5199), ('en', 4340), ('y', 4235)]\n"
     ]
    }
   ],
   "source": [
    "comments = [comment.strip() for comment in comments if comment.strip()]\n",
    "\n",
    "def top_n_words(comments, n=8):\n",
    "    from collections import Counter\n",
    "    words = [word for comment in comments for word in comment.split()]\n",
    "    return Counter(words).most_common(n)\n",
    "\n",
    "print(\"Top 8 common words:\")\n",
    "print(top_n_words(comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d8b764",
   "metadata": {},
   "source": [
    "Para verificar si será necesario aplicar la transformación de mayusculas a mínusculas, se desarrolla una función que permite observar si una palabra tiene una equivalente en con algún caracter en mayúscula o minúscula en el corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "60a17a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with case variations:\n",
      "Variantes de 'el': {'EL', 'el', 'El'}\n",
      "Variantes de 'grupo': {'Grupo', 'grupo'}\n",
      "Variantes de 'anunció': {'Anunció', 'anunció'}\n"
     ]
    }
   ],
   "source": [
    "def encontrar_variaciones_de_casing(comments, max_resultados=3):\n",
    "    formas_por_palabra = {}\n",
    "    resultados_mostrados = 0\n",
    "\n",
    "    for comment in comments:\n",
    "        for word in comment.split():\n",
    "            base = word.lower()\n",
    "            if base not in formas_por_palabra:\n",
    "                formas_por_palabra[base] = set()\n",
    "            formas_por_palabra[base].add(word)\n",
    "\n",
    "    for base, formas in formas_por_palabra.items():\n",
    "        if len(formas) > 1:\n",
    "            print(f\"Variantes de '{base}': {formas}\")\n",
    "            resultados_mostrados += 1\n",
    "            if resultados_mostrados >= max_resultados:\n",
    "                break\n",
    "\n",
    "\n",
    "print(\"Words with case variations:\")\n",
    "encontrar_variaciones_de_casing(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96550e1c",
   "metadata": {},
   "source": [
    "Observamos que sí existen casos con variantes mayusculas y minusculas, por lo que sí se considera necesaria su aplicación. Además, se procede a analizar si ocurre lo mismo pero con signos de puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1529afb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with punctuation variations:\n",
      "Variantes de puntuación para '': {'!', '¿', '...', '¡', \"'\", '?', '.', '\"', ':', ';', ','}\n",
      "Variantes de puntuación para 'PP': {'PP', 'PP.'}\n",
      "Variantes de puntuación para '2': {'2', '2.'}\n"
     ]
    }
   ],
   "source": [
    "def encontrar_variaciones_de_puntuacion(comments, max_resultados=3):\n",
    "    formas_por_palabra = {}\n",
    "    resultados_mostrados = 0\n",
    "    signos = \".!?,;:()\\\"'¿¡\"\n",
    "\n",
    "    for comment in comments:\n",
    "        for word in comment.split():\n",
    "            base = word.strip(signos)\n",
    "            if base not in formas_por_palabra:\n",
    "                formas_por_palabra[base] = set()\n",
    "            formas_por_palabra[base].add(word)\n",
    "\n",
    "    for base, formas in formas_por_palabra.items():\n",
    "        if len(formas) > 1:\n",
    "            print(f\"Variantes de puntuación para '{base}': {formas}\")\n",
    "            resultados_mostrados += 1\n",
    "            if resultados_mostrados >= max_resultados:\n",
    "                break\n",
    "\n",
    "print(\"Words with punctuation variations:\")\n",
    "encontrar_variaciones_de_puntuacion(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553985a",
   "metadata": {},
   "source": [
    "De esta forma identificamos que también se producen ocurrencias, por lo que se aplica el procedimiento de eliminación de puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "79daeefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erasePunctuation(comments):\n",
    "    return [re.sub(r'[^\\w\\s]', '', line) for line in comments]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe0d71f",
   "metadata": {},
   "source": [
    "Se procede con la estandarización y se evalua el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "01dedf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 8 common words after standardization:\n",
      "[('de', 10286), ('la', 6925), ('el', 6013), ('que', 5570), ('en', 4643), ('y', 4349), ('los', 3189), ('a', 3020)]\n"
     ]
    }
   ],
   "source": [
    "comments = [comment.lower() for comment in comments]\n",
    "comments = erasePunctuation(comments)\n",
    "print(\"Top 8 common words after standardization:\")\n",
    "print(top_n_words(comments))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8db181",
   "metadata": {},
   "source": [
    "Se puede apreciar que existe un aumento en la frecuencia de algunas palabras, por lo tanto, la estandarización es efectiva. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "680c4a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['el grupo estatal electricité_de_france edf anunció hoy  jueves  la compra del 51_por_ciento de la empresa mexicana electricidad_águila_de_altamira eaa  creada por el japonés mitsubishi_corporation para poner_en_marcha una central de gas de 495 megavatios ',\n",
       " 'una portavoz de edf explicó a efe que el proyecto para la construcción de altamira_2  al norte de tampico  prevé la utilización de gas natural como combustible principal en una central de ciclo combinado que debe empezar a funcionar en mayo_del_2002 ',\n",
       " 'la electricidad producida pasará a la red eléctrica pública de méxico en_virtud_de un acuerdo de venta de energía de eaa con la comisión_federal_de_electricidad cfe por una duración de 25 años ',\n",
       " 'edf  que no quiso revelar cuánto pagó por su participación mayoritaria en eaa  intervendrá como asistente en la construcción de altamira_2 y  posteriormente  se encargará de explotarla como principal accionista ',\n",
       " 'edf y mitsubishi participaron en 1998 en la licitación de licencias para construir centrales eléctricas en méxico y se quedaron con dos cada una  río_bravo y saltillo para la compañía francesa y altamira y tuxpán para la japonesa ',\n",
       " 'edf tiene previsto invertir 194 millones de euros 186 millones de dólares en la central de río_bravo  con una potencia de 495 megavatios  y 134 millones de euros 28 millones de dólares en saltillo  que como la primera funcionará con gas natural y cuya potencia prevista es de 247 megavatios ',\n",
       " 'la alcaldesa de málaga y cabeza de lista del pp al congreso por esta provincia  celia_villalobos  pidió hoy a los militantes de esta formación que sepan  administrar la victoria   porque  no vale la revancha  el insulto o el ataque  eso es para ellos  ',\n",
       " 'en una intervención ante militantes populares en el hotel de la capital malagueña elegido como sede de la noche electoral del pp  villalobos dio las gracias  a los militantes de muchos años que hoy tienen una emoción especial   y se confesó también  especialmente emocionada  en sus quintas elecciones generales ',\n",
       " 'la diputada electa transmitió  un abrazo y mi cariño a josé_maría_aznar   a quien definió como  el hombre que ha sabido llevar al pp hasta la victoria   y dio las gracias a la  gente que ha sabido ilusionar y convencer a muchos para que apuesten  por este partido ',\n",
       " 'a todas estas personas  no las vamos a defraudar   aseguró villalobos  que subrayó que aznar  seguirá gobernando desde el diálogo  sin prepotencia  con honradez y preocupado por los problemas  y seguiremos siendo los mismos  ']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2cbe31",
   "metadata": {},
   "source": [
    "Finalmente se identifica que existen secuencias de 2 o más espacios en blanco en la separación de algunas palabras, para evitar obtener bigramas incorrectos o que en algun punto de la estandarización afecten, se procede a normalizarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fc16e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeSpaces(lines):\n",
    "    return [re.sub(r'\\s+', ' ', line).strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ff2ea16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['el grupo estatal electricité_de_france edf anunció hoy jueves la compra del 51_por_ciento de la empresa mexicana electricidad_águila_de_altamira eaa creada por el japonés mitsubishi_corporation para poner_en_marcha una central de gas de 495 megavatios',\n",
       " 'una portavoz de edf explicó a efe que el proyecto para la construcción de altamira_2 al norte de tampico prevé la utilización de gas natural como combustible principal en una central de ciclo combinado que debe empezar a funcionar en mayo_del_2002',\n",
       " 'la electricidad producida pasará a la red eléctrica pública de méxico en_virtud_de un acuerdo de venta de energía de eaa con la comisión_federal_de_electricidad cfe por una duración de 25 años',\n",
       " 'edf que no quiso revelar cuánto pagó por su participación mayoritaria en eaa intervendrá como asistente en la construcción de altamira_2 y posteriormente se encargará de explotarla como principal accionista',\n",
       " 'edf y mitsubishi participaron en 1998 en la licitación de licencias para construir centrales eléctricas en méxico y se quedaron con dos cada una río_bravo y saltillo para la compañía francesa y altamira y tuxpán para la japonesa',\n",
       " 'edf tiene previsto invertir 194 millones de euros 186 millones de dólares en la central de río_bravo con una potencia de 495 megavatios y 134 millones de euros 28 millones de dólares en saltillo que como la primera funcionará con gas natural y cuya potencia prevista es de 247 megavatios',\n",
       " 'la alcaldesa de málaga y cabeza de lista del pp al congreso por esta provincia celia_villalobos pidió hoy a los militantes de esta formación que sepan administrar la victoria porque no vale la revancha el insulto o el ataque eso es para ellos',\n",
       " 'en una intervención ante militantes populares en el hotel de la capital malagueña elegido como sede de la noche electoral del pp villalobos dio las gracias a los militantes de muchos años que hoy tienen una emoción especial y se confesó también especialmente emocionada en sus quintas elecciones generales',\n",
       " 'la diputada electa transmitió un abrazo y mi cariño a josé_maría_aznar a quien definió como el hombre que ha sabido llevar al pp hasta la victoria y dio las gracias a la gente que ha sabido ilusionar y convencer a muchos para que apuesten por este partido',\n",
       " 'a todas estas personas no las vamos a defraudar aseguró villalobos que subrayó que aznar seguirá gobernando desde el diálogo sin prepotencia con honradez y preocupado por los problemas y seguiremos siendo los mismos']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = normalizeSpaces(comments)\n",
    "comments[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804160f9",
   "metadata": {},
   "source": [
    "De esta forma se procede a almacenar el corpus estandarizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b27be755",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for comment in comments:\n",
    "        file.write(comment + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901658df",
   "metadata": {},
   "source": [
    "## Construcción de modelos de n-gramas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d150d95",
   "metadata": {},
   "source": [
    "Los modelos basados en bigramas requieren de una tokenización de los elementos para luego ser procesados mediante la formula condicional P(wn | wn-1, ... , wn-k+1) usando frecuencias relativas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1978a35",
   "metadata": {},
   "source": [
    "Con ayuda de nltk se construye un modelo de conteo condicional que permite calcular por cada palabra wn, cuántas veces aparece wn-1 después de la misma. Lo cual permite realizar el calculo de las probabilidades condicionales contando el total de ocurrencias por cada wn, usandolo como denominador de la frecuencia mencionada anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68034061",
   "metadata": {},
   "source": [
    "Básicamente, se construyen los modelos en base a la siguiente fórmula:\n",
    "\n",
    "\\[\n",
    "P(w_n \\mid w_{n-1}, \\dots, w_{n-k+1}) = \\frac{C(w_{n-k+1}, \\dots, w_n)}{C(w_{n-k+1}, \\dots, w_{n-1})}\n",
    "\\]\n",
    "\n",
    "donde \\(k = 1, 2, 3\\)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "aeb39f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['el',\n",
       " 'grupo',\n",
       " 'estatal',\n",
       " 'electricité_de_france',\n",
       " 'edf',\n",
       " 'anunció',\n",
       " 'hoy',\n",
       " 'jueves',\n",
       " 'la',\n",
       " 'compra']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga y tokenización del corpus estandarizado\n",
    "with open(\"corpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "tokens = []\n",
    "for line in lines:\n",
    "    words = line.strip().split()\n",
    "    tokens.extend(words)\n",
    "\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bbb2b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNgramModel(comments, n):\n",
    "    tokens = []\n",
    "    for sentence in comments:\n",
    "        tokens.extend(sentence.strip().split())\n",
    "\n",
    "    ngram_list = list(ngrams(tokens, n))\n",
    "    cfd = ConditionalFreqDist()\n",
    "\n",
    "    for ng in ngram_list:\n",
    "        context = () if n == 1 else tuple(ng[:-1])\n",
    "        word = ng[0] if n == 1 else ng[-1]\n",
    "        cfd[context][word] += 1\n",
    "\n",
    "    model = {}\n",
    "    for context in cfd:\n",
    "        model[context] = {\n",
    "            '__total__': cfd[context].N()\n",
    "        }\n",
    "        for word in cfd[context]:\n",
    "            model[context][word] = cfd[context][word]\n",
    "\n",
    "    vocab = set(tokens)\n",
    "    return model, len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7a9a1a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramsProbability = []\n",
    "n = [1, 2, 3]\n",
    "for n_size in n:\n",
    "    bigramProbability, vocabSizeC = trainNgramModel(comments, n_size)\n",
    "    bigramsProbability.append(bigramProbability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b0e03e",
   "metadata": {},
   "source": [
    "## Análisis de espacidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d104adf5",
   "metadata": {},
   "source": [
    "Aunque en el ejercicio anterior se construyeron modelos de n-gramas sobre todo el corpus, para este análisis de espacidad es necesario separar una parte del corpus como conjunto de prueba. Esto permite evaluar cuántos n-gramas nuevos aparecen que no fueron observados en los datos de entrenamiento, lo cual es esencial para entender las limitaciones de los modelos. La separación se realizará con 75% entrenamiento y 25% prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "91aea06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitIndex = int(len(comments) * 0.75)\n",
    "train_comments = comments[:splitIndex]\n",
    "test_comments = comments[splitIndex:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "20e47a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramsProbability = []\n",
    "for n_size in n:\n",
    "    bigramProbability, vocabSizeC = trainNgramModel(train_comments, n_size)\n",
    "    bigramsProbability.append(bigramProbability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d8fe428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgrams(comments, n):\n",
    "    tokens = []\n",
    "    for sentence in comments:\n",
    "        tokens.extend(sentence.strip().split())\n",
    "    return list(ngrams(tokens, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "bdfe94f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateSparsity(model, test_comments, n):\n",
    "    test_ngrams = getNgrams(test_comments, n)\n",
    "    total = len(test_ngrams)\n",
    "    missing = 0\n",
    "\n",
    "    for ng in test_ngrams:\n",
    "        context = () if n == 1 else tuple(ng[:-1])\n",
    "        word = ng[0] if n == 1 else ng[-1]\n",
    "\n",
    "        if context not in model or word not in model[context]:\n",
    "            missing += 1\n",
    "\n",
    "    return (missing / total) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "542333c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espacidad para n=1: 16.26% de n-gramas no vistos\n",
      "Espacidad para n=2: 62.92% de n-gramas no vistos\n",
      "Espacidad para n=3: 92.60% de n-gramas no vistos\n"
     ]
    }
   ],
   "source": [
    "for i, n_size in enumerate(n):\n",
    "    model = bigramsProbability[i]\n",
    "    sparsity = calculateSparsity(model, test_comments, n_size)\n",
    "    print(f\"Espacidad para n={n_size}: {sparsity:.2f}% de n-gramas no vistos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33dc412",
   "metadata": {},
   "source": [
    "Se infiere con esto que a mayor valor de n, mayor espacidad: el modelo necesita más combinaciones de palabras. De esta forma se limita la capacidad del modelo de generar texto o calcular la probabilidad para frases que son nuevas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde9b39",
   "metadata": {},
   "source": [
    "## Implementación de suavizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e333b07",
   "metadata": {},
   "source": [
    "El suavizado en modelos de n-gramas es una técnica que ajusta las probabilidades para que incluso los n-gramas no observados tengan una probabilidad distinta de cero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd608f0",
   "metadata": {},
   "source": [
    "### Suavizado de laplace"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f200bafd",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0f321ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplaceSmoothedProbability(model, context, word, vocab_size):\n",
    "    count = model.get(context, {}).get(word, 0)\n",
    "    total = model.get(context, {}).get('__total__', 0)\n",
    "    return (count + 1) / (total + vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44674164",
   "metadata": {},
   "source": [
    "### Interpolación lineal"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "dfa80a2d",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "188e8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolatedProbability(uni_model, bi_model, tri_model, context, word, vocab_size, lambdas=(0.4, 0.4, 0.2)):\n",
    "    lambda3, lambda2, lambda1 = lambdas\n",
    "    unigram = ()\n",
    "    bigram = (context[-1],) if len(context) >= 1 else ()\n",
    "    trigram = context if len(context) >= 2 else ()\n",
    "    p1 = laplaceSmoothedProbability(uni_model, unigram, word, vocab_size)\n",
    "    p2 = laplaceSmoothedProbability(bi_model, bigram, word, vocab_size)\n",
    "    p3 = laplaceSmoothedProbability(tri_model, trigram, word, vocab_size)\n",
    "    return lambda1 * p1 + lambda2 * p2 + lambda3 * p3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672e722",
   "metadata": {},
   "source": [
    "### Kneser-Ney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "38169249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainKneserNeyModel(tokens, n):\n",
    "    train_data, vocab = padded_everygram_pipeline(n, [tokens])\n",
    "    model = KneserNeyInterpolated(order=n)\n",
    "    model.fit(train_data, vocab)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8e95a3",
   "metadata": {},
   "source": [
    "Antes de realizar la implementación, los modelos se entrenarán en este caso con todo el corpus ya que en incisos posteriores lo que se busca evaluar es la perplejidad por lo que no existe la necesidad de hacer la separación en train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "99e9a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramsProbability = []\n",
    "bigramsVocabSize = []\n",
    "n = [1, 2, 3]\n",
    "for n_size in n:\n",
    "    bigramProbability, vocabSizeC = trainNgramModel(comments, n_size)\n",
    "    bigramsProbability.append(bigramProbability)\n",
    "    bigramsVocabSize.append(vocabSizeC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "340b441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kneser_models = [trainKneserNeyModel(tokens, n) for n in [1, 2, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f49ba3",
   "metadata": {},
   "source": [
    "## Cálculo de perplejidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ab7a9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePerplexityLaplace(tokens, model, vocab_size, n):\n",
    "    import math\n",
    "    N = len(tokens)\n",
    "    if N < n:\n",
    "        return float('inf')\n",
    "\n",
    "    log_prob_sum = 0.0\n",
    "    for i in range(N - n + 1):\n",
    "        ngram = tuple(tokens[i:i + n])\n",
    "        context = () if n == 1 else tuple(ngram[:-1])\n",
    "        word = ngram[0] if n == 1 else ngram[-1]\n",
    "\n",
    "        prob = laplaceSmoothedProbability(model, context, word, vocab_size)\n",
    "        log_prob_sum += math.log(prob)\n",
    "\n",
    "    return math.exp(-log_prob_sum / (N - n + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "48068ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePerplexityInterpolated(tokens, uni_model, bi_model, tri_model, vocab_size, lambdas=(0.2, 0.3, 0.5)):\n",
    "    import math\n",
    "    N = len(tokens)\n",
    "    if N < 3:\n",
    "        return float('inf')\n",
    "\n",
    "    log_prob_sum = 0.0\n",
    "    for i in range(N - 3 + 1):\n",
    "        ngram = tuple(tokens[i:i + 3])\n",
    "        context = ngram[:-1]\n",
    "        word = ngram[-1]\n",
    "\n",
    "        prob = interpolatedProbability(uni_model, bi_model, tri_model, context, word, vocab_size, lambdas)\n",
    "        log_prob_sum += math.log(prob)\n",
    "\n",
    "    return math.exp(-log_prob_sum / (N - 3 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c3b6663a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>Laplace</th>\n",
       "      <th>Interpolación</th>\n",
       "      <th>Kneser-Ney</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>497.11</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3454.97</td>\n",
       "      <td>—</td>\n",
       "      <td>307.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14720.46</td>\n",
       "      <td>691.0</td>\n",
       "      <td>670.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n   Laplace Interpolación Kneser-Ney\n",
       "0  1    497.11             —          —\n",
       "1  2   3454.97             —     307.78\n",
       "2  3  14720.46         691.0      670.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = \"el proyecto de la construcción es grande y complejo\"\n",
    "sentence_tokens = sentence.strip().split()\n",
    "\n",
    "# Tabla vacía\n",
    "tabla_perplejidad = {\n",
    "    \"n\": [],\n",
    "    \"Laplace\": [],\n",
    "    \"Interpolación\": [],\n",
    "    \"Kneser-Ney\": []\n",
    "}\n",
    "\n",
    "for i, n_size in enumerate(n):\n",
    "    tabla_perplejidad[\"n\"].append(n_size)\n",
    "\n",
    "    # === Laplace ===\n",
    "    model_laplace = bigramsProbability[i]\n",
    "    vocab_laplace = bigramsVocabSize[i]\n",
    "    ppl_laplace = calculatePerplexityLaplace(sentence_tokens, model_laplace, vocab_laplace, n_size)\n",
    "    tabla_perplejidad[\"Laplace\"].append(round(ppl_laplace, 2))\n",
    "\n",
    "    # === Interpolación (solo para n = 3) ===\n",
    "    if n_size == 3:\n",
    "        ppl_interp = calculatePerplexityInterpolated(\n",
    "            sentence_tokens,\n",
    "            bigramsProbability[0],\n",
    "            bigramsProbability[1],\n",
    "            bigramsProbability[2],\n",
    "            vocab_laplace\n",
    "        )\n",
    "        tabla_perplejidad[\"Interpolación\"].append(round(ppl_interp, 2))\n",
    "    else:\n",
    "        tabla_perplejidad[\"Interpolación\"].append(\"—\")\n",
    "\n",
    "    # === Kneser-Ney usando model.perplexity() de nltk.lm ===\n",
    "    if n_size == 1:\n",
    "        tabla_perplejidad[\"Kneser-Ney\"].append(\"—\")\n",
    "    else:\n",
    "        test_ngrams = list(ngrams(sentence_tokens, n_size))\n",
    "        ppl_kn = kneser_models[i].perplexity(test_ngrams)\n",
    "        tabla_perplejidad[\"Kneser-Ney\"].append(round(ppl_kn, 2))\n",
    "\n",
    "# Mostrar la tabla\n",
    "df_perplejidad = pd.DataFrame(tabla_perplejidad)\n",
    "display(df_perplejidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7886f02",
   "metadata": {},
   "source": [
    "## Generación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ee316253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTextLaplace(model, vocab, vocab_size, n, seed, length=15):\n",
    "    generated = seed.strip().split()\n",
    "    for _ in range(length):\n",
    "        context = tuple(generated[-(n-1):]) if n > 1 else ()\n",
    "        probs = {}\n",
    "        for word in vocab:\n",
    "            prob = laplaceSmoothedProbability(model, context, word, vocab_size)\n",
    "            probs[word] = prob\n",
    "        next_word = random.choices(list(probs.keys()), weights=probs.values())[0]\n",
    "        generated.append(next_word)\n",
    "    return ' '.join(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "31f7cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTextInterpolated(unigrams, bigrams, trigrams, vocab, n, seed, length):\n",
    "    generated = seed.strip().split()\n",
    "\n",
    "    for _ in range(length):\n",
    "        # Asegura que el contexto tiene la longitud adecuada\n",
    "        context = tuple(generated[-(n-1):]) if len(generated) >= n-1 else tuple(generated)\n",
    "        \n",
    "        probs = {}\n",
    "        for word in vocab:\n",
    "            prob = interpolatedProbability(\n",
    "                unigrams, bigrams, trigrams,\n",
    "                context,\n",
    "                word,\n",
    "                len(vocab)\n",
    "            )\n",
    "            probs[word] = prob\n",
    "\n",
    "        # Selección ponderada\n",
    "        next_word = random.choices(list(probs.keys()), weights=probs.values())[0]\n",
    "        generated.append(next_word)\n",
    "\n",
    "    return ' '.join(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a1a76c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTextKneserNey(model, n, seed, length=15):\n",
    "    generated = seed.strip().split()\n",
    "    context = tuple(generated[-(n-1):]) if n > 1 else ()\n",
    "\n",
    "    # Usamos directamente .generate con num_words=length y el context inicial\n",
    "    generated_words = list(model.generate(length, text_seed=context))\n",
    "\n",
    "    # Unimos el seed original con las nuevas palabras generadas\n",
    "    return ' '.join(generated + generated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4ce7458c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- n = 1 ---\n",
      "Laplace:\n",
      "el su sobre_todo cristal quede depor de los la él guatemaltecos particular europeo sur de la\n",
      "\n",
      "--- n = 2 ---\n",
      "Laplace:\n",
      "el bienestar arg estuvo presiona consumo proyecta desdoro denunció tirarla obligados bateo girar rencor fuerza_armada 4b\n",
      "\n",
      "Kneser-Ney:\n",
      "el rey_juan_carlos se mostró convencido de ajuste de contratación ya_que puede criticar porque lo que sobre\n",
      "\n",
      "--- n = 3 ---\n",
      "Laplace:\n",
      "el monetario abren rendimiento extraño 4p sentado tony_rominger tamaños kim_dae_jung mafiosa indeseados de_tarde_en_tarde entiende caballería utilitario\n",
      "\n",
      "Interpolación:\n",
      "el heroicidad especialistas almorzando ariete al_cabo_de remitir evitar caracolean castigada simpática trato objetivos ojo aplacar aún\n",
      "\n",
      "Kneser-Ney:\n",
      "el de su puesta en marcha de la tierra y han estado marcados por insultos personales\n"
     ]
    }
   ],
   "source": [
    "seed = \"el\"\n",
    "length = 15\n",
    "\n",
    "all_tokens = []\n",
    "for sentence in comments:\n",
    "    all_tokens.extend(sentence.strip().split())\n",
    "\n",
    "vocabulario = set(all_tokens)\n",
    "\n",
    "for i, n_size in enumerate(n):\n",
    "    print(f\"\\n--- n = {n_size} ---\")\n",
    "\n",
    "    # Laplace\n",
    "    print(\"Laplace:\")\n",
    "    print(generateTextLaplace(bigramsProbability[i], vocabulario, bigramsVocabSize[i], n_size, seed, length))\n",
    "\n",
    "    # Interpolación (solo para n=3)\n",
    "    if n_size == 3:\n",
    "        print(\"\\nInterpolación:\")\n",
    "        print(generateTextInterpolated(\n",
    "            bigramsProbability[0],\n",
    "            bigramsProbability[1],\n",
    "            bigramsProbability[2],\n",
    "            vocabulario,\n",
    "            n_size,\n",
    "            seed,\n",
    "            length\n",
    "        ))\n",
    "\n",
    "    # Kneser-Ney\n",
    "    if n_size >= 2:\n",
    "        model = kneser_models[i]\n",
    "        print(\"\\nKneser-Ney:\")\n",
    "        print(generateTextKneserNey(model, n_size, seed, length))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c943d35",
   "metadata": {},
   "source": [
    "## Discusión final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1e857",
   "metadata": {},
   "source": [
    "Los resultados evidencian cómo las distintas técnicas de suavizado afectan significativamente la perplejidad del modelo. El suavizado de Laplace genera perplejidades excesivamente altas a medida que aumenta el valor de n, especialmente en n=3 donde supera los 14,000. Esto indica que este método no maneja adecuadamente la esparsidad en n-gramas a medida que n es mayor. En cambio, otras técnicas como la Interpolación (691.0) y Kneser-Ney (670.7) logran una mejor distribución de probabilidad, reduciendo considerablemente la perplejidad y reflejando un mejor rendimiento estadístico del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8c04ae",
   "metadata": {},
   "source": [
    "A medida que aumenta n, los modelos pueden considerar más contexto anterior, lo cual mejora la fluidez y coherencia del texto generado. Con n=1 (Laplace), el texto resulta desorganizado y con poca estructura. Para n=2, los modelos empiezan a generar frases parcialmente coherentes. Finalmente, con n=3, los textos generados mediante Interpolación y Kneser-Ney presentan oraciones más naturales y con una mejor conexión entre palabras. Esto sugiere que la capacidad de modelar el contexto largo, combinada con un suavizado efectivo, mejora sustancialmente la calidad del lenguaje generado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5d366",
   "metadata": {},
   "source": [
    "La esparsidad tiene un impacto directo y severo en el rendimiento de los modelos. Cuando el corpus no contiene suficientes combinaciones posibles de palabras, los modelos sin un buen suavizado (como Laplace) asignan malas probabilidades, elevando la perplejidad y afectando la generación de texto. Modelos como Kneser-Ney son menos vulnerables a este problema, ya que estiman la probabilidad de un n-grama basándose también en cómo aparecen las palabras en otros contextos, permitiendo una mejor generalización incluso con datos escasos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
