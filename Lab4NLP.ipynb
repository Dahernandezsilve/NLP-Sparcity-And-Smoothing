{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7f6821",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <td style=\"width:20%; vertical-align:middle;\">\n",
    "      <img src=\"LogoUVG.png\" width=\"400\"/>\n",
    "    </td>\n",
    "    <td style=\"text-align:left; vertical-align:middle;\">\n",
    "      <h2 style=\"margin-bottom: 0;\">Universidad del Valle de Guatemala - UVG</h2>\n",
    "      <h3 style=\"margin-top: 0;\">Facultad de Ingeniería - Computación</h3>\n",
    "      <p style=\"font-size: 16px; margin-bottom: 0; margin-top: -20px\">\n",
    "        <strong>Curso:</strong> Procesamiento de Lenguaje Natural \n",
    "        <strong>Sección:</strong> 10\n",
    "      </p>\n",
    "      <p style=\"font-size: 16px; margin: 0;\"><strong>Laboratorio 4:</strong> Modelos de Lenguaje con N-gramas, Espacidad y Suavizado</p>\n",
    "      <br>\n",
    "      <p style=\"font-size: 15px; margin: 0;\"><strong>Autor:</strong></p>\n",
    "      <ul style=\"margin-top: 5px; padding-left: 20px; font-size: 15px;\">\n",
    "        <li>Diego Alexander Hernández Silvestre - <strong>21270</strong></li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('cess_esp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams, ngrams, ConditionalFreqDist\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import cess_esp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f93e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CESS-ESP corpus\n",
    "corpus = cess_esp.sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577ca94",
   "metadata": {},
   "source": [
    "Un elemento detectado es que el corpus utiliza marcas para identificar patrones sintácticos. Por ejemplo -Fpa-, -Fpt- y *0*, pero como el objetivo del laboratorio es generar texto fluido con bigramas, se procede a filtrarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpecialTags(sentences):\n",
    "    \"\"\"\n",
    "    Elimina tokens como -Fpa-, -Fpt- (rodeados por guiones)\n",
    "    y tokens como *0*, *1* (placeholders de anotación sintáctica)\n",
    "    en el corpus cess_esp.\n",
    "    \"\"\"\n",
    "    cleaned = []\n",
    "    for sentence in sentences:\n",
    "        cleaned_sentence = [\n",
    "            word for word in sentence\n",
    "            if not (word.startswith('-') and word.endswith('-'))  # -Fpa-, -Fpt-\n",
    "            and not re.fullmatch(r\"\\*\\d+\\*\", word)                # *0*, *1*, etc.\n",
    "        ]\n",
    "        cleaned.append(cleaned_sentence)\n",
    "    return cleaned\n",
    "\n",
    "comments = removeSpecialTags(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83958d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [' '.join(sent) for sent in comments]\n",
    "comments[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46eb6af",
   "metadata": {},
   "source": [
    "# Estandarización del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a940be",
   "metadata": {},
   "source": [
    "Se buscar analizar el efecto de la estandarización para identificar si existen apariciones de nuevas palabras con más repeticiones o simplemente, aumenta el número de las que actualmente se encuentran como más frecuentes. Para esto, se mostraran las 8 palabras más frecuentes antes del proceso y después del mismo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b54a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [comment.strip() for comment in comments if comment.strip()]\n",
    "\n",
    "def top_n_words(comments, n=8):\n",
    "    from collections import Counter\n",
    "    words = [word for comment in comments for word in comment.split()]\n",
    "    return Counter(words).most_common(n)\n",
    "\n",
    "print(\"Top 8 common words:\")\n",
    "print(top_n_words(comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d8b764",
   "metadata": {},
   "source": [
    "Para verificar si será necesario aplicar la transformación de mayusculas a mínusculas, se desarrolla una función que permite observar si una palabra tiene una equivalente en con algún caracter en mayúscula o minúscula en el corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a17a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_variaciones_de_casing(comments, max_resultados=3):\n",
    "    formas_por_palabra = {}\n",
    "    resultados_mostrados = 0\n",
    "\n",
    "    for comment in comments:\n",
    "        for word in comment.split():\n",
    "            base = word.lower()\n",
    "            if base not in formas_por_palabra:\n",
    "                formas_por_palabra[base] = set()\n",
    "            formas_por_palabra[base].add(word)\n",
    "\n",
    "    for base, formas in formas_por_palabra.items():\n",
    "        if len(formas) > 1:\n",
    "            print(f\"Variantes de '{base}': {formas}\")\n",
    "            resultados_mostrados += 1\n",
    "            if resultados_mostrados >= max_resultados:\n",
    "                break\n",
    "\n",
    "\n",
    "print(\"Words with case variations:\")\n",
    "encontrar_variaciones_de_casing(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96550e1c",
   "metadata": {},
   "source": [
    "Observamos que sí existen casos con variantes mayusculas y minusculas, por lo que sí se considera necesaria su aplicación. Además, se procede a analizar si ocurre lo mismo pero con signos de puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_variaciones_de_puntuacion(comments, max_resultados=3):\n",
    "    formas_por_palabra = {}\n",
    "    resultados_mostrados = 0\n",
    "    signos = \".!?,;:()\\\"'¿¡\"\n",
    "\n",
    "    for comment in comments:\n",
    "        for word in comment.split():\n",
    "            base = word.strip(signos)\n",
    "            if base not in formas_por_palabra:\n",
    "                formas_por_palabra[base] = set()\n",
    "            formas_por_palabra[base].add(word)\n",
    "\n",
    "    for base, formas in formas_por_palabra.items():\n",
    "        if len(formas) > 1:\n",
    "            print(f\"Variantes de puntuación para '{base}': {formas}\")\n",
    "            resultados_mostrados += 1\n",
    "            if resultados_mostrados >= max_resultados:\n",
    "                break\n",
    "\n",
    "print(\"Words with punctuation variations:\")\n",
    "encontrar_variaciones_de_puntuacion(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553985a",
   "metadata": {},
   "source": [
    "De esta forma identificamos que también se producen ocurrencias, por lo que se aplica el procedimiento de eliminación de puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79daeefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erasePunctuation(comments):\n",
    "    return [re.sub(r'[^\\w\\s]', '', line) for line in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceUnderscore(comments):\n",
    "    return [line.replace('_', ' ') for line in comments]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe0d71f",
   "metadata": {},
   "source": [
    "Se procede con la estandarización y se evalua el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dedf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [comment.lower() for comment in comments]\n",
    "comments = erasePunctuation(comments)\n",
    "\n",
    "print(\"Top 8 common words after standardization:\")\n",
    "print(top_n_words(comments))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8db181",
   "metadata": {},
   "source": [
    "Se puede apreciar que existe un aumento en la frecuencia de algunas palabras, por lo tanto, la estandarización es efectiva. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680c4a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2cbe31",
   "metadata": {},
   "source": [
    "Finalmente se identifica que existen varios epacios en blanco en la separación de algunas palabras, para evitar obtener bigramas incorrectos o que en algun punto de la estandarización afecten, se procede a normalizarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc16e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeSpaces(lines):\n",
    "    \"\"\"\n",
    "    Reemplaza múltiples espacios en blanco seguidos por un solo espacio.\n",
    "    También elimina espacios iniciales/finales si los hay.\n",
    "    \"\"\"\n",
    "    return [re.sub(r'\\s+', ' ', line).strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2ea16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = normalizeSpaces(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b689ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804160f9",
   "metadata": {},
   "source": [
    "De esta forma se procede a almacenar el corpus estandarizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27be755",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for comment in comments:\n",
    "        file.write(comment + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901658df",
   "metadata": {},
   "source": [
    "## Modelo basado en bigramas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d150d95",
   "metadata": {},
   "source": [
    "Los modelos basados en bigramas requieren de una tokenización de los elementos para luego ser procesados mediante la formula condicional P(w2 | w1) usando frecuencias relativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb39f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga y tokenización del corpus estandarizado\n",
    "with open(\"corpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "tokens = []\n",
    "for line in lines:\n",
    "    words = line.strip().split()\n",
    "    tokens.extend(words)\n",
    "\n",
    "tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a86f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de bigramas\n",
    "bigramsCorpus = list(bigrams(tokens))\n",
    "bigramsCorpus[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd106f8a",
   "metadata": {},
   "source": [
    "Con ayuda de nltk se construye un modelo de conteo condicional que permite calcular por cada palabra w1, cuántas veces aparece w2 después de la misma. Lo cual permite realizar el calculo de las probabilidades condicionales contando el total de ocurrencias por cada w1, usandolo como denominador de la frecuencia mencionada anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadade0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción del modelo de conteo condicional\n",
    "cfd = ConditionalFreqDist(bigramsCorpus)\n",
    "\n",
    "bigramsProbability = {}\n",
    "for w1 in cfd.conditions():\n",
    "    total = cfd[w1].N()\n",
    "    bigramsProbability[w1] = {}\n",
    "    for w2 in cfd[w1]:\n",
    "        prob = cfd[w1][w2] / total\n",
    "        bigramsProbability[w1][w2] = prob  \n",
    "\n",
    "# Mostrar las probabilidades condicionales de los 10 bigramas más frecuentes\n",
    "bigramCount = Counter()\n",
    "\n",
    "for w1 in cfd.conditions():\n",
    "    for w2 in cfd[w1]:\n",
    "        bigramCount[(w1, w2)] = cfd[w1][w2]\n",
    "\n",
    "topBigrams = bigramCount.most_common(10)\n",
    "\n",
    "print(\"\\nTop 10 bigramas más frecuentes con probabilidad condicional:\")\n",
    "for (w1, w2), count in topBigrams:\n",
    "    total_w1 = cfd[w1].N()\n",
    "    prob = count / total_w1\n",
    "    print(f\"- P({w2}|{w1}) = {prob:.4f}  ({count} ocurrencias)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a828528e",
   "metadata": {},
   "source": [
    "## Generador de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362911c0",
   "metadata": {},
   "source": [
    "Ahora se procede a realizar una función generadora de texto que permita generar una secuencia a partir del modelo lenguaje basado en bigramas. La forma en la que trabaja este es que a partir de una palabra inicial, se obtienen todas las posibles que pueden seguirlas en base a las probabilidades de los bigramas, entonces se escoge una de ellas aleatoriamente (en un enfoque estocástico) y se toma ahora esta como palabra inicial. Este proceso es repetido hasta llegar a la longitud determinada por el usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateText(startWord, length=10):\n",
    "    \"\"\"\n",
    "    Genera una secuencia de texto basada en bigramas a partir de una palabra inicial.\n",
    "    \"\"\"\n",
    "    if startWord not in bigramsProbability:\n",
    "        print(f\"La palabra '{startWord}' no está en el vocabulario.\")\n",
    "        return \"\"\n",
    "\n",
    "    currentWord = startWord\n",
    "    text = [currentWord]\n",
    "\n",
    "    for _ in range(length - 1):\n",
    "        nextWords = list(bigramsProbability.get(currentWord, {}).keys())\n",
    "        if not nextWords:\n",
    "            break\n",
    "        nextWord = random.choices(nextWords, weights=bigramsProbability[currentWord].values())[0]\n",
    "        text.append(nextWord)\n",
    "        currentWord = nextWord\n",
    "\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ee0291",
   "metadata": {},
   "source": [
    "Entonces como ejemplo de uso se decide usar la palabra \"de\" como inicial ya que se determinó en el proceso de estandarización del corpus como más frecuente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598fddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "textGenerated = generateText(\"de\", length=20)\n",
    "print(\"\\nTexto generado:\")\n",
    "print(textGenerated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a98387",
   "metadata": {},
   "source": [
    "## Perplejidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766bcd2",
   "metadata": {},
   "source": [
    "La perplejidad es una medida que evalúa qué tan bien un modelo de lenguaje predice una secuencia. Mientras más baja, mejor es el modelo para esa secuencia.\n",
    "\n",
    "Sin embargo, si una combinación condicional no aparece en el corpus, su probabilidad será de 0 y su perplejidad por lo tanto infinita, por esta razón la solución para esto es el suavizado de laplace que calcula probabilidades en base al tamaño del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed97ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabSize(corpus):\n",
    "    \"\"\"\n",
    "    Calcula el tamaño del vocabulario del corpus.\n",
    "    \"\"\"\n",
    "    unique_words = set()\n",
    "    for sentence in corpus:\n",
    "        unique_words.update(sentence.split())\n",
    "    return len(unique_words)\n",
    "\n",
    "def calculatePerplexity(sentence, bigramsProbability, vocabSize):\n",
    "    \"\"\"\n",
    "    Calcula la perplejidad de una secuencia de texto dada.\n",
    "    \"\"\"\n",
    "    tokens = sentence.split()\n",
    "    N = len(tokens)\n",
    "    \n",
    "    if N == 0:\n",
    "        return float('inf')  # Perplejidad infinita para secuencias vacías\n",
    "\n",
    "    log_prob_sum = 0.0\n",
    "    for i in range(N - 1):\n",
    "        w1, w2 = tokens[i], tokens[i + 1]\n",
    "        prob = bigramsProbability.get(w1, {}).get(w2, 0)\n",
    "        if prob == 0:\n",
    "            prob = 1 / (vocabSize + 1)  # Suavizado de Laplace\n",
    "        log_prob_sum += math.log(prob)\n",
    "\n",
    "    perplexity = math.exp(-log_prob_sum / (N - 1))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b7b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"el proyecto de la construcción\"\n",
    "vocabSizeC = vocabSize(comments)\n",
    "pp = calculatePerplexity(sentence, bigramsProbability, vocabSizeC)\n",
    "print(f\"Perplejidad: {pp:.4f}\")\n",
    "\n",
    "sentence = \"los niños juegan en el parque\"\n",
    "pp = calculatePerplexity(sentence, bigramsProbability, vocabSizeC)\n",
    "print(f\"Perplejidad: {pp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b868bd",
   "metadata": {},
   "source": [
    "Al interpretar los resultados se evidencia que la primera oración tiene una perplejidad mucho menor que la segunda. Esto indica que el modelo considera este grupo de palabras como más probable dentro del corpus, lo cual sugiere que los bigramas observados aparecen con mayor frecuencia.\n",
    "\n",
    "Por contraparte, la segunda oración tiene una perplejidad significativamente más alta probablemente porque sus bigramas son poco prefuentes o porque directamente no aparecen en el corpus, por lo que su probabilidad está estimada en base al suvizado de Laplace. \n",
    "\n",
    "Con lo cual, podemos determinar que el corpus está centrado en un lenguaje quizá más técnico y orientado a temas específicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d884cf77",
   "metadata": {},
   "source": [
    "## Evaluación de la perplejidad con diferentes tamaños de corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b76766",
   "metadata": {},
   "source": [
    "Se entrenaran modelos con corpus al 1%, 5%, 10%, 50% y 100% para evaluar la perplejidad sobre una misma oración de prueba con el objetivo de ver visualmente si a medida que se aumenta el porcentaje del corpues, la perplejidad sobre la oración se va reduciendo. Para esto se generará una pipeline de entrenamiento y visualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc571934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBigramModel(comments):\n",
    "    tokens = []\n",
    "    for sentence in comments:\n",
    "        tokens.extend(sentence.strip().split())\n",
    "\n",
    "    bigrams_list = list(bigrams(tokens))\n",
    "    cfd = ConditionalFreqDist(bigrams_list)\n",
    "\n",
    "    bigramsProbability = {}\n",
    "    for w1 in cfd.conditions():\n",
    "        total = cfd[w1].N()\n",
    "        bigramsProbability[w1] = {}\n",
    "        for w2 in cfd[w1]:\n",
    "            prob = cfd[w1][w2] / total\n",
    "            bigramsProbability[w1][w2] = prob\n",
    "\n",
    "    return bigramsProbability, len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatePerplexityOverSizes(comments, testSentence, sizes=[0.01, 0.05, 0.1, 0.5, 1.0]):\n",
    "    results = []\n",
    "    for size in sizes:\n",
    "        subset_size = int(len(comments) * size)\n",
    "        comments = random.sample(comments, subset_size)\n",
    "        bigramsProbability, vocabSizeC = trainBigramModel(comments)\n",
    "        pp = calculatePerplexity(testSentence, bigramsProbability, vocabSizeC)\n",
    "        results.append((size, pp))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e2195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPerplexityResults(results):\n",
    "    sizes, perplexities = zip(*results)\n",
    "    percentLabels = [f\"{s* 100:.0f}%\" for s in sizes]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sizes, perplexities, marker='o')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Tamaño del corpus (%)')\n",
    "    plt.ylabel('Perplejidad')\n",
    "    plt.title('Perplejidad vs Tamaño del Corpus')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(sizes, percentLabels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6371688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"el proyecto de la construcción es grande y complejo\"\n",
    "results = evaluatePerplexityOverSizes(comments, sentence)\n",
    "plotPerplexityResults(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237322d3",
   "metadata": {},
   "source": [
    "Con 1% del corpus, la perplejidad es muy alta sobrepasando 400, lo que indica que el modelo tiene muy poca información para poder predecir correctamente las transiciones entre palabras. Cuando se llega al 5% y 10% se observa una reducción significativa de la perplejidad, lo cual muestra que el modelo ya es capaz de reconocer patrones útiles y a partir del 10% en adelante, la perplejidad se estabiliza cerca de 0, lo cual sugiere que la oración se encuentra cubierta por el modelo y agregar más datos no mejorará significativamente los resultados para esta oración."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b60d514",
   "metadata": {},
   "source": [
    "## Evaluación con 3-gramas, 4-gramas y 5-gramas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9abc8f1",
   "metadata": {},
   "source": [
    "Se busca evaluar cómo cambia el modelo al aumentar el contexto de las palabras, comparar la perplejidad con la del modelo de bigramas y ver si mejora el rendimiento en las oraciones de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNgramModel(comments, n):\n",
    "    tokens = []\n",
    "    for sentence in comments:\n",
    "        tokens.extend(sentence.strip().split())\n",
    "\n",
    "    ngram_list = list(ngrams(tokens, n))\n",
    "    cfd = ConditionalFreqDist()\n",
    "\n",
    "    for ng in ngram_list:\n",
    "        context = tuple(ng[:-1])\n",
    "        word = ng[-1]             \n",
    "        cfd[context][word] += 1\n",
    "\n",
    "    model = {}\n",
    "    for context in cfd:\n",
    "        total = cfd[context].N()\n",
    "        model[context] = {}\n",
    "        for word in cfd[context]:\n",
    "            model[context][word] = cfd[context][word] / total\n",
    "\n",
    "    vocab = set(tokens)\n",
    "    return model, len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa5397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateNgramPerplexity(sentence, ngramsProbability, vocabSize, n):\n",
    "    tokens = sentence.split()\n",
    "    N = len(tokens)\n",
    "    \n",
    "    if N < n:\n",
    "        return float('inf')\n",
    "\n",
    "    log_prob_sum = 0.0\n",
    "    for i in range(N - n + 1):\n",
    "        ngram = tuple(tokens[i:i + n])\n",
    "        prob = ngramsProbability.get(ngram[:-1], {}).get(ngram[-1], 0)\n",
    "        if prob == 0:\n",
    "            prob = 1 / (vocabSize + 1)\n",
    "        log_prob_sum += math.log(prob)\n",
    "\n",
    "    perplexity = math.exp(-log_prob_sum / (N - n + 1))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNgramPerplexity(results):\n",
    "    n_vals, perplexities = zip(*results)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(n_vals, perplexities, marker='o')\n",
    "    plt.title(\"Perplejidad vs Tamaño del N-grama\")\n",
    "    plt.xlabel(\"Tamaño del N-grama\")\n",
    "    plt.ylabel(\"Perplejidad\")\n",
    "    plt.grid(True)\n",
    "    plt.xticks(n_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b155e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatePerplexityOverNgramSizes(comments, testSentence, n=[2, 3, 4, 5]):\n",
    "    results = []\n",
    "    for n_size in n:\n",
    "        bigramsProbability, vocabSizeC = trainNgramModel(comments, n_size)\n",
    "        pp = calculateNgramPerplexity(testSentence, bigramsProbability, vocabSizeC, n_size)\n",
    "        results.append((n_size, pp))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"el proyecto de la construcción es grande y complejo\"\n",
    "results = evaluatePerplexityOverNgramSizes(comments, sentence)\n",
    "plotNgramPerplexity(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61bc29d",
   "metadata": {},
   "source": [
    "Se observa que medida que el valor de n aumenta, la perplejidad también lo hace significativamente, especialmente entre los 3-gramas y los 4-gramas. Esto se debe a que con valores más altos de n, se vuelve menos probable que el modelo haya detectectado esa secuencia de palabras en el corpus, provocando muchos casos de probabiliid suavizada, lo cual aumenta la respectiva perplejidad. \n",
    "\n",
    "Aunque los modelos con n-gramas más largos podrían capturar dependencias más complejas entre palabras, requieren un corpus más grande y diverso para ser efectivos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc5bf42",
   "metadata": {},
   "source": [
    "## Efecto del tamaño del corpus y valor de n sombre el desempeño de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3bc28",
   "metadata": {},
   "source": [
    "En los modelos evaluados, se observó que el tamaño del corpus tiene una fuerte relación en el tamaño de la perplejidad ya que a medida que se incrementa el porcentaje de corpus, la perplejidad se reduce significativamente. Esto es debido a que corpus más grandes permiten al modelo observar más combinaciones de palabras, lo cual reduce en parte el uso del suavizado y mejora la estimación de probabilidades para ciertos grupos de oraciones.\n",
    "\n",
    "Por otro lado, el valor de n en los n-gramas también influye en el desempeño de los modelos. A medida que este valor crece, el modelo requiere más contexto para realizar predicciones más precisas. Esto puede provocar un aumento de perplejidad si el corpus no es lo suficientementne grande como para cubrir con todas las posibles combinaciones. En este caso con un corpus que no es muy amplio, es más útil emplear ordenes menores de n para contar un mejor equilibrio entre la precisión y la cobretura.\n",
    "\n",
    "De esta forma, se determina que para obtener mejores valores de perplejidad sobre distintas oraciones de prueba, se requiere un corpus más grande a medida que aumenta el valor de n y en corpus pequeños, los bigramas y trigramas tienden a ser más eficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ff9df",
   "metadata": {},
   "source": [
    "## Esparsidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745856f7",
   "metadata": {},
   "source": [
    "La esparsidad ocurre cuando muchas combinaciones posibles de palabras no aparecen en el corpus evaluado. Esto es más evidente en modelos con n-gramas de mayor orden (como los que se observan en las gráficas con el 4 o el 5), donde requieren de un contexto más amplio y por lo tanto secuencias más específicas. Resultado de esto es un incremento en la perplejidad porque el modelo no es capaz de asignar buenas probabilidades a secuencias no tan frecuentes. Incluso se puede ver más limitado cuando el corpus es más pequeño.\n",
    "\n",
    "De esta forma, la esparsidad es un valor clave a considera cuando se trabaja con corpus pequeños o medianos ya que limita el rendimiento con n-gramas de orden alto afectando directamente su capacidad de generalizar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
